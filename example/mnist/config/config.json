{
  "batch_size": 100,
  "epoch": 100,
  "learning_rate": 0.001,
  "weight_decay": 0.001,
  "layers": [100, 100],
  "gpu": -1,
  "output_dir": "result/mlp"
}
